
Assignment 5: due March 31 (11:59 pm)

In this assignment, you will implement a variational auto-encoder (VAE) and a generative adversarial network (GAN) in PyTorch to generate images similar to those in the MNIST dataset. As a starting point, the code for a deterministic auto-encoder (DAE) is provided. While DAEs achieve good reconstruction of the original images, they struggle to generate new images that are similar to those in MNIST. Implement a VAE and GAN to generate better images. Download the skeleton code for this assignment:

Part 1: cs480_winter23_asst5_vae_skeleton.ipynb

Part 2: cs480_winter23_asst5_gan_skeleton.ipynb

Fill in the functions in each skeleton notebook and answer the following questions in each notebook. Submit the Jupyter notebooks via LEARN.


Part 1 (7 points): VAE implementation in cs480_winter23_asst5_vae_skeleton.ipynb. Fill in the functions and save the following results in your Jupyter notebook:

Two graphs that each contain 2 curves (DAE and VAE). The first graph displays the training reconstruction loss and the second graph displays the testing reconstruction loss. In both graphs, the y-axis is binary cross entropy and the x-axis is the number of epochs.

Print a sample of generated images after each epoch of training for both DAEs and VAEs.

Explanation of the results (i.e., compare and explain the binary cross entropy and the quality of the sampled images generated by DAEs and VAEs).

Part 2 (8 points): GAN implementation in cs480_winter23_asst5_gan_skeleton.ipynb. Checkout the following tutorial for GANs. Fill in the functions and save the following results in your Jupyter notebook:

Two graphs that each contain 2 curves (Generator and Discriminator losses). The first graph displays the training loss and the second graph displays the testing loss. In both graphs, the y-axis is binary cross entropy and the x-axis is the number of epochs.

Print a sample of generated images after each epoch of training for your GAN.

Explanation of the results (i.e., compare and explain the quality of the sampled images generated by VAEs and GANs).
